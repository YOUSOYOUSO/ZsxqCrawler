import random
import time
from typing import Any, Callable, Dict, List

from modules.shared.db_path_manager import get_db_path_manager
from modules.zsxq.zsxq_file_downloader import ZSXQFileDownloader
from api.services.group_filter_service import apply_group_scan_filter, format_group_filter_summary


class GlobalFileTaskService:
    """å…¨åŒºæ–‡ä»¶æ”¶é›†/ä¸‹è½½æœåŠ¡ï¼ˆä» main.py æ‹†å‡ºä¸šåŠ¡æµç¨‹ï¼‰ã€‚"""

    def run_collect(
        self,
        task_id: str,
        add_task_log: Callable[[str, str], None],
        update_task: Callable[..., Any],
        is_task_stopped: Callable[[str], bool],
        get_cookie_for_group: Callable[[str], str],
        file_downloader_instances: Dict[str, Any],
    ) -> None:
        """æ‰§è¡Œå…¨åŒºæ–‡ä»¶åˆ—è¡¨æ”¶é›†æµç¨‹ã€‚"""
        try:
            update_task(task_id, "running", "å‡†å¤‡å¼€å§‹å…¨åŒºæ–‡ä»¶æ”¶é›†...")
            add_task_log(task_id, "ğŸš€ å¼€å§‹å…¨åŒºæ–‡ä»¶åˆ—è¡¨æ”¶é›†")

            manager = get_db_path_manager()
            all_groups = manager.list_all_groups()
            filtered = apply_group_scan_filter(all_groups)
            groups = filtered["included_groups"]
            excluded_groups = filtered["excluded_groups"]
            reason_counts = filtered["reason_counts"]
            default_action = filtered["default_action"]
            for line in format_group_filter_summary(
                all_groups,
                groups,
                excluded_groups,
                reason_counts,
                default_action,
            ):
                add_task_log(task_id, line)

            if not groups:
                update_task(task_id, "completed", "å…¨åŒºæ”¶é›†å®Œæˆ: è¿‡æ»¤åæ— å¯æ‰«æç¾¤ç»„")
                return

            processed_groups = 0
            for i, group in enumerate(groups, 1):
                if is_task_stopped(task_id):
                    add_task_log(task_id, "ğŸ›‘ ä»»åŠ¡å·²è¢«ç”¨æˆ·åœæ­¢")
                    break

                group_id = str(group["group_id"])
                add_task_log(task_id, "")
                add_task_log(task_id, f"ğŸ‘‰ [{i}/{len(groups)}] æ­£åœ¨æ”¶é›†ç¾¤ç»„ {group_id} çš„æ–‡ä»¶åˆ—è¡¨...")

                try:
                    cookie = get_cookie_for_group(group_id)
                    db_path = manager.get_files_db_path(group_id)

                    downloader = ZSXQFileDownloader(cookie, group_id, db_path)
                    downloader.log_callback = lambda msg: add_task_log(task_id, f"   {msg}")
                    downloader.stop_check_func = lambda: is_task_stopped(task_id)

                    file_downloader_instances[task_id] = downloader
                    res = downloader.collect_incremental_files()

                    add_task_log(
                        task_id,
                        f"   âœ… ç¾¤ç»„ {group_id} æ–‡ä»¶æ”¶é›†å®Œæˆ! æ–°å¢å¾…ä¸‹è½½: {res.get('new_files', 0) if isinstance(res, dict) else res}",
                    )
                    processed_groups += 1
                except Exception as ge:
                    add_task_log(task_id, f"   âŒ ç¾¤ç»„ {group_id} æ”¶é›†å¼‚å¸¸: {ge}")
                finally:
                    if task_id in file_downloader_instances:
                        del file_downloader_instances[task_id]

                if i < len(groups) and not is_task_stopped(task_id):
                    sleep_time = random.uniform(1.0, 3.0)
                    add_task_log(task_id, f"â³ ç­‰å¾… {sleep_time:.1f} ç§’...")
                    time.sleep(sleep_time)

            if is_task_stopped(task_id):
                update_task(task_id, "cancelled", "å…¨åŒºæ”¶é›†å·²åœæ­¢")
            else:
                add_task_log(task_id, "")
                add_task_log(task_id, "=" * 50)
                add_task_log(task_id, f"ğŸ‰ å…¨åŒºæ–‡ä»¶åˆ—è¡¨æ”¶é›†å®Œæˆï¼å…±å¤„ç† {processed_groups}/{len(groups)} ä¸ªç¾¤ç»„")
                update_task(task_id, "completed", f"å…¨åŒºæ”¶é›†å®Œæˆ: {processed_groups} ä¸ªç¾¤ç»„")
        except Exception as e:
            add_task_log(task_id, f"âŒ å…¨åŒºæ”¶é›†å¼‚å¸¸: {e}")
            update_task(task_id, "failed", f"å…¨åŒºæ”¶é›†å¤±è´¥: {e}")

    def run_download(
        self,
        task_id: str,
        request: Any,
        add_task_log: Callable[[str, str], None],
        update_task: Callable[..., Any],
        is_task_stopped: Callable[[str], bool],
        get_cookie_for_group: Callable[[str], str],
        file_downloader_instances: Dict[str, Any],
    ) -> None:
        """æ‰§è¡Œå…¨åŒºæ–‡ä»¶ä¸‹è½½æµç¨‹ã€‚"""
        try:
            update_task(task_id, "running", "å‡†å¤‡å¼€å§‹å…¨åŒºä¸‹è½½...")
            add_task_log(task_id, "ğŸš€ å¼€å§‹å…¨åŒºæ–‡ä»¶ä¸‹è½½")

            manager = get_db_path_manager()
            all_groups = manager.list_all_groups()
            filtered = apply_group_scan_filter(all_groups)
            groups = filtered["included_groups"]
            excluded_groups = filtered["excluded_groups"]
            reason_counts = filtered["reason_counts"]
            default_action = filtered["default_action"]
            for line in format_group_filter_summary(
                all_groups,
                groups,
                excluded_groups,
                reason_counts,
                default_action,
            ):
                add_task_log(task_id, line)

            if not groups:
                update_task(task_id, "completed", "å…¨åŒºä¸‹è½½å®Œæˆ: è¿‡æ»¤åæ— å¯æ‰«æç¾¤ç»„")
                return

            processed_groups = 0
            for i, group in enumerate(groups, 1):
                if is_task_stopped(task_id):
                    add_task_log(task_id, "ğŸ›‘ ä»»åŠ¡å·²è¢«ç”¨æˆ·åœæ­¢")
                    break

                group_id = str(group["group_id"])
                add_task_log(task_id, "")
                add_task_log(task_id, f"ğŸ‘‰ [{i}/{len(groups)}] æ­£åœ¨ä¸‹è½½ç¾¤ç»„ {group_id} çš„æ–‡ä»¶...")

                try:
                    cookie = get_cookie_for_group(group_id)
                    db_path = manager.get_files_db_path(group_id)

                    downloader = ZSXQFileDownloader(
                        cookie=cookie,
                        group_id=group_id,
                        db_path=db_path,
                        download_interval=request.download_interval,
                        long_sleep_interval=request.long_sleep_interval,
                        files_per_batch=request.files_per_batch,
                        download_interval_min=request.download_interval_min,
                        download_interval_max=request.download_interval_max,
                        long_sleep_interval_min=request.long_sleep_interval_min,
                        long_sleep_interval_max=request.long_sleep_interval_max,
                    )
                    downloader.log_callback = lambda msg: add_task_log(task_id, f"   {msg}")
                    downloader.stop_check_func = lambda: is_task_stopped(task_id)

                    file_downloader_instances[task_id] = downloader
                    res = downloader.download_files(request.max_files, sort_by=request.sort_by)

                    dl_success = res.get("downloaded", 0) if isinstance(res, dict) else res
                    add_task_log(task_id, f"   âœ… ç¾¤ç»„ {group_id} ä¸‹è½½å®Œæˆ! æˆåŠŸ: {dl_success}")
                    processed_groups += 1
                except Exception as ge:
                    add_task_log(task_id, f"   âŒ ç¾¤ç»„ {group_id} ä¸‹è½½å¼‚å¸¸: {ge}")
                finally:
                    if task_id in file_downloader_instances:
                        del file_downloader_instances[task_id]

            if is_task_stopped(task_id):
                update_task(task_id, "cancelled", "å…¨åŒºä¸‹è½½å·²åœæ­¢")
            else:
                add_task_log(task_id, "")
                add_task_log(task_id, "=" * 50)
                add_task_log(task_id, f"ğŸ‰ å…¨åŒºæ–‡ä»¶ä¸‹è½½å®Œæˆï¼å…±å¤„ç† {processed_groups}/{len(groups)} ä¸ªç¾¤ç»„")
                update_task(task_id, "completed", f"å…¨åŒºä¸‹è½½å®Œæˆ: {processed_groups} ä¸ªç¾¤ç»„")
        except Exception as e:
            add_task_log(task_id, f"âŒ å…¨åŒºä¸‹è½½å¼‚å¸¸: {e}")
            update_task(task_id, "failed", f"å…¨åŒºä¸‹è½½å¤±è´¥: {e}")
