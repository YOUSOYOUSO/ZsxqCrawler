import time
from typing import Any, Callable, Dict, List

from modules.shared.db_path_manager import get_db_path_manager
from modules.analyzers.global_analyzer import get_global_analyzer
from modules.analyzers.stock_analyzer import StockAnalyzer
from api.services.group_filter_service import apply_group_scan_filter, format_group_filter_summary


class GlobalAnalyzePerformanceService:
    """å…¨åŒºæ”¶ç›Šè®¡ç®—æœåŠ¡ï¼ˆä» main.py æ‹†å‡ºä¸šåŠ¡æµç¨‹ï¼‰ã€‚"""

    def run(
        self,
        task_id: str,
        add_task_log: Callable[[str, str], None],
        update_task: Callable[..., Any],
        is_task_stopped: Callable[[str], bool],
        calc_window_days: int = 365,
    ) -> None:
        """æ‰§è¡Œå…¨åŒºæ”¶ç›Šè®¡ç®—ä¸»æµç¨‹ã€‚"""
        try:
            update_task(task_id, "running", "å‡†å¤‡å¼€å§‹å…¨åŒºæ”¶ç›Šè®¡ç®—...")
            add_task_log(task_id, "ğŸš€ å¼€å§‹å…¨åŒºæåŠæ”¶ç›Šåˆ·æ–°")

            manager = get_db_path_manager()
            all_groups = manager.list_all_groups()
            filtered = apply_group_scan_filter(all_groups)
            groups = filtered["included_groups"]
            excluded_groups = filtered["excluded_groups"]
            reason_counts = filtered["reason_counts"]
            default_action = filtered["default_action"]

            for line in format_group_filter_summary(
                all_groups,
                groups,
                excluded_groups,
                reason_counts,
                default_action,
            ):
                add_task_log(task_id, line)

            if not groups:
                update_task(task_id, "completed", "å…¨åŒºæ”¶ç›Šè®¡ç®—å®Œæˆ: è¿‡æ»¤åæ— å¯æ‰«æç¾¤ç»„")
                return

            processed_groups = 0
            groups_with_auto_extract = 0
            mentions_extracted_total = 0
            performance_processed_total = 0

            for i, group in enumerate(groups, 1):
                if is_task_stopped(task_id):
                    add_task_log(task_id, "ğŸ›‘ ä»»åŠ¡å·²è¢«ç”¨æˆ·åœæ­¢")
                    break

                group_id = str(group["group_id"])
                add_task_log(task_id, "")
                add_task_log(task_id, f"ğŸ‘‰ [{i}/{len(groups)}] æ­£åœ¨è®¡ç®—ç¾¤ {group_id} çš„æ”¶ç›Š...")

                try:
                    analyzer = StockAnalyzer(group_id)
                    backlog = analyzer._get_analysis_backlog_stats(calc_window_days=calc_window_days)
                    add_task_log(
                        task_id,
                        f"   ğŸ§© é¢„æ£€æŸ¥: mentions={backlog.get('mentions_total', 0)}, pending={backlog.get('pending_total', 0)}",
                    )

                    # æ¯æ¬¡æ”¶ç›Šè®¡ç®—å‰éƒ½å…ˆåšä¸€æ¬¡å¢é‡æå–ï¼Œé¿å…â€œå·²æœ‰å¾…ç®—ä»»åŠ¡æ—¶è·³è¿‡æå–â€å¯¼è‡´æ–°è¯é¢˜æ¼ç®—
                    extract_res = analyzer.extract_only()
                    extracted_mentions = int(extract_res.get("mentions_extracted", 0) or 0)
                    new_topics = int(extract_res.get("new_topics", 0) or 0)
                    if new_topics > 0 or extracted_mentions > 0:
                        groups_with_auto_extract += 1
                    mentions_extracted_total += extracted_mentions
                    add_task_log(
                        task_id,
                        f"   ğŸ“ è‡ªåŠ¨æå–: new_topics={new_topics}, mentions={extracted_mentions}, unique_stocks={extract_res.get('unique_stocks', 0)}",
                    )

                    last_log_time = 0.0

                    def progress_cb(current: int, total: int, status: str):
                        nonlocal last_log_time
                        now = time.time()
                        # é¿å…æ—¥å¿—è¿‡å¤šï¼Œåªåœ¨ä»»åŠ¡å¯åŠ¨æˆ–ä¸€å®šæ—¶é—´åæ‰“å°
                        if now - last_log_time >= 5 or current == total or current == 1:
                            add_task_log(task_id, f"   â³ è¿›åº¦: {current}/{total} - {status}")
                            last_log_time = now

                    res = analyzer.calc_pending_performance(
                        calc_window_days=calc_window_days,
                        progress_callback=progress_cb,
                    )
                    processed_count = int(res.get("processed", 0) or 0)
                    skipped_count = int(res.get("skipped", 0) or 0)
                    error_count = int(res.get("errors", 0) or 0)
                    performance_processed_total += processed_count
                    add_task_log(
                        task_id,
                        f"   âœ… ç¾¤ç»„ {group_id} æ”¶ç›Šè®¡ç®—å®Œæˆ! processed={processed_count}, skipped={skipped_count}, errors={error_count}",
                    )
                    processed_groups += 1
                except Exception as ge:
                    add_task_log(task_id, f"   âŒ ç¾¤ç»„ {group_id} è®¡ç®—å¼‚å¸¸: {ge}")

            if is_task_stopped(task_id):
                update_task(task_id, "cancelled", "å…¨åŒºè®¡ç®—å·²åœæ­¢")
            else:
                add_task_log(task_id, "")
                add_task_log(task_id, "=" * 50)
                add_task_log(task_id, f"ğŸ‰ å…¨åŒºæ”¶ç›Šè®¡ç®—å®Œæˆï¼å…±å¤„ç† {processed_groups}/{len(groups)} ä¸ªç¾¤ç»„")
                add_task_log(
                    task_id,
                    f"ğŸ“Š è‡ªåŠ¨æå–ç¾¤ç»„: {groups_with_auto_extract}, è‡ªåŠ¨æå–æåŠ: {mentions_extracted_total}, æ”¶ç›Šå¤„ç†æ¡æ•°: {performance_processed_total}",
                )

                try:
                    get_global_analyzer().invalidate_cache()
                    add_task_log(task_id, "ğŸ”„ å…¨å±€ç»Ÿè®¡ç¼“å­˜å·²åˆ·æ–°")
                except Exception:
                    pass

                update_task(
                    task_id,
                    "completed",
                    f"å…¨åŒºæ”¶ç›Šè®¡ç®—å®Œæˆ: {processed_groups} ä¸ªç¾¤ç»„",
                    {
                        "groups_processed": processed_groups,
                        "groups_total": len(groups),
                        "groups_with_auto_extract": groups_with_auto_extract,
                        "mentions_extracted_total": mentions_extracted_total,
                        "performance_processed_total": performance_processed_total,
                    },
                )

        except Exception as e:
            add_task_log(task_id, f"âŒ å…¨åŒºè®¡ç®—å¼‚å¸¸: {e}")
            update_task(task_id, "failed", f"å…¨åŒºè®¡ç®—å¤±è´¥: {e}")
